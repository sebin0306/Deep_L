import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.autograd import Variable
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np

# "": 현재폴더에 mnist 있음
mnist_train=dset.MNIST("",train=True,transform=transforms.ToTensor(),target_transform=None,download=True)
mnist_test=dset.MNIST("",train=False,transform=transforms.ToTensor(),target_transform=None, download=True)

print "mnist_train 길이:", len(mnist_train)
print "mnist_test 길이:", len(mnist_test)

image,label=mnist_train.__getitem__(0)
print "image data 형태:",image.size()
print "label: ", label

img=image.numpy()
plt.title("label: %d" %label )
plt.imshow(img[0],cmap='gray')
plt.show()

batch_size =1024
learning_rate = 0.01
num_epoch=400

train_loader = torch.utils.data.DataLoader(mnist_train,
                                           batch_size=batch_size,
                                          shuffle=True,num_workers=2,
                                          drop_last=True)
test_loader = torch.utils.data.DataLoader(mnist_test,
                                           batch_size=batch_size,
                                          shuffle=False,num_workers=2,
                                          drop_last=True)
                                          
n =3
for i, [imgs, labels] in enumerate(test_loader):
    if i>5:
        break
        
    print"[%d]" %i
    print "한번에 로드되는 데이터 크기:", len(imgs)
    
    for j in range(n):
        img = imgs[j].numpy()
        img = img.reshape((img.shape[1], img.shape[2]))
        
        plt.subplot(1,n,j+1)
        plt.imshow(img, cmap='gray')
        plt.title("label: %d" %labels[j])
    plt.show()

model = nn.Sequential(
    nn.Linear(28*28,256),
    nn.Sigmoid(),
    nn.Linear(256,128),
    nn.Linear(128,10),
)

def ComputeAccr(dloader, imodel):
    correct = 0
    total = 0
    
    for j, [imgs,labels] in enumerate(dloader):
        img = imgs
        label = Variable(labels)
        #label = Variable(labels),cuda()
        #.cuda() : GPU에 로드되기 위함. 만약 CPU로 설정되어있으면 에러남
        
        #(batch_size, 1, 28,28) -> (batch_size, 28,28)
        img = img.reshape((img.shape[0], img.shape[2],img.shape[3]))
        #(batch_size, 28,28) -> (batch_size, 28*28)
        img = img.reshape((img.shape[0], img.shape[1]*img.shape[2]))
        img = Variable(img, requires_grad=False)
        #img = Variable(img, requires_grad=False),cuda()
        
        output = imodel(img) #forward prop.
        _, output_index = torch.max(output, 1)
        
        total+=label.size(0)
        correct += (output_index == label).sum().float()
    print("Accuracy of Test Data: {}". format(100*correct/total))
 
 ComputeAccr(test_loader, model)
 
 loss_func = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=learning_rate)

for i in range(num_epoch):
    for j, [imgs, labels] in enumerate(train_loader):
        img = imgs
        label = Variable(labels)
        
        
        img  = img.reshape((img.shape[0], img.shape[2], img.shape[3]))
        img  = img.reshape((img.shape[0], img.shape[1]*img.shape[2]))
        img =Variable(img, requires_grad=True)
        
        optimizer.zero_grad()
        output = model(img)
        loss = loss_func(output, label)
        
        loss.backward()
        optimizer.step()
        
    if i%50==0:
        print("%d.." %i)
        ComputeAccr(test_loader,model)
        print loss
        
 ComputeAccr(test_loader, model)
 
 netname = './nets/mlp_weight.pkl'
torch.save(model, netname, )

#model = torch.load(netname)
