{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b15b8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c2814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 #64 #1\n",
    "learning_rate = 0.0001\n",
    "epoch = 20\n",
    "\n",
    "n_node=1024 #customized last layer의 노드의 수. 64,128, 256, 512, 1024\n",
    "dropratio = 0.5 #얼마나 드랍시킬지 inverse keepratio\n",
    "\n",
    "imgsize = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79ac3082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "#img_dir = \"../../../imges/painting_datasets/real_artwork/real_artwork_divided_shffl_4K/Train\"\n",
    "img_dir = \"fruit/train\"\n",
    "train_data = dset.ImageFolder(img_dir, transforms.Compose([\n",
    "             transforms.CenterCrop(imgsize*2),\n",
    "             transforms.RandomCrop(imgsize),\n",
    "             transforms.RandomHorizontalFlip(),\n",
    "    \n",
    "             transforms.Resize(imgsize),\n",
    "             transforms.ToTensor()\n",
    "             ]))\n",
    "print(train_data.__len__())\n",
    "\n",
    "train_batch = data.DataLoader(train_data, batch_size=batch_size,\n",
    "                             shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d04c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Dev data\n",
    "#img_dir = \"../../../imges/painting_datasets/real_artwork/real_artwork_divided_shffl_4K/Valid\"\n",
    "img_dir = \"fruit/val\"\n",
    "dev_data = dset.ImageFolder(img_dir, transforms.Compose([\n",
    "           #transforms.Scale(256),\n",
    "           #transforms.RandomSizeCrop(224),\n",
    "           \n",
    "           transforms.CenterCrop(size=imgsize),\n",
    "           transforms.Resize(imgsize),\n",
    "           transforms.ToTensor()\n",
    "           ]))\n",
    "\n",
    "dev_batch = data.DataLoader(dev_data, batch_size=batch_size,\n",
    "                             shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad77dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Test data\n",
    "img_dir = \"fruit/test\"\n",
    "test_data = dset.ImageFolder(img_dir, transforms.Compose([\n",
    "           #transforms.Scale(256),\n",
    "           #transforms.RandomSizeCrop(224),\n",
    "           \n",
    "           transforms.CenterCrop(size=imgsize),\n",
    "           transforms.Resize(imgsize),\n",
    "           transforms.ToTensor()\n",
    "           ]))\n",
    "\n",
    "test_batch = data.DataLoader(test_data, batch_size=batch_size,\n",
    "                             shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18849fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#of classes: 2\n",
      "['kmelon', 'watermelon']\n",
      "{'watermelon': 1, 'kmelon': 0}\n",
      "38\n",
      "Training: 38, Dev: 13, Test: 12\n"
     ]
    }
   ],
   "source": [
    "nclass = len(train_data.classes)\n",
    "print(\"#of classes: %d\" %nclass)\n",
    "print(train_data.classes)\n",
    "print(train_data.class_to_idx)\n",
    "print(train_data.__len__())\n",
    "\n",
    "print(\"Training: %d, Dev: %d, Test: %d\"\n",
    "     %(train_data.__len__(),dev_data.__len__(),test_data.__len__())),\n",
    "\n",
    "#for imgs, labels in train_batch:\n",
    "#   for j in range(len(imgs)):\n",
    "#       img = transforms.ToPILImage()(imgs[j])\n",
    "#       plt.title(\"label:%d\" % labels[j])\n",
    "#       plt.imshow(img)\n",
    "#       plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f754c7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kmelon', 'watermelon']\n",
      "['kmelon', 'watermelon']\n",
      "['kmelon', 'watermelon']\n"
     ]
    }
   ],
   "source": [
    "print(train_data.classes)\n",
    "print(dev_data.classes)\n",
    "print(test_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8598f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\n",
      "avgpool\n",
      "classifier\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace=True)\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (24): ReLU(inplace=True)\n",
      "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (26): ReLU(inplace=True)\n",
      "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): ReLU(inplace=True)\n",
      "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (33): ReLU(inplace=True)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): ReLU(inplace=True)\n",
      "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg = models.vgg19(pretrained=True)\n",
    "\n",
    "for name,module in vgg.named_children():\n",
    "    print(name)\n",
    "    \n",
    "print(list(vgg.children())[0])\n",
    "print(list(vgg.children())[-1])\n",
    "\n",
    "#cnt = 0\n",
    "#for i in model.children():\n",
    "#   print(\"yhk[%d]\"%cnt),\n",
    "#   print(i)\n",
    "#   cnt = cnt+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2a26ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customized Fully Model\n",
    "base_dim = 64\n",
    "fsize = imgsize/32\n",
    "\n",
    "class MyVGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyVGG,self).__init__()\n",
    "        #[0]: features(conv), [1]:classifier(fc)\n",
    "        self.layer0 = nn.Sequential(*list(vgg.children())[0])\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(8*base_dim*fsize*fsize, n_node),\n",
    "            nn.BatchNorm1d(n_node),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropratio),\n",
    "            \n",
    "            nn.Linear(n_node, n_node),\n",
    "            nn.BatchNorm1d(n_node),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropratio),\n",
    "            \n",
    "            nn.Linear(n_node, n_node),\n",
    "            nn.BatchNorm1d(n_node),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(dropratio),\n",
    "            \n",
    "            nn.Linear(n_node, nclass),\n",
    "        )\n",
    "        #weight initialization\n",
    "        for m in self.layer1.modules():\n",
    "            #print(m)\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal(m.weight.data) #ReLU 일 때\n",
    "                m.bias.data.fill_(0)\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal(m.weight.data) #ReLU 일 때\n",
    "                m.bias.data.fill_(0)\n",
    "    def forward(self,x):\n",
    "        #layer0의 사이즈를 무식하게 프린트하여 알아낼 수 있음(batchsize, x,x,x)\n",
    "        #print(x,size())\n",
    "        out = self.layer0(x)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.layer1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3281a171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/ipykernel/__main__.py:36: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n"
     ]
    }
   ],
   "source": [
    "#3)Model on GPU\n",
    "\n",
    "model = MyVGG()#.cuda()\n",
    "\n",
    "for params in model.layer0.parameters():\n",
    "    params.required_grad = False\n",
    "\n",
    "for params in model.layer1.parameters():\n",
    "    params.required_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1c9c8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace=True)\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (24): ReLU(inplace=True)\n",
      "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (26): ReLU(inplace=True)\n",
      "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): ReLU(inplace=True)\n",
      "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (33): ReLU(inplace=True)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): ReLU(inplace=True)\n",
      "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=32768, out_features=1024, bias=True)\n",
      "  (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout2d(p=0.5, inplace=False)\n",
      "  (4): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU()\n",
      "  (7): Dropout2d(p=0.5, inplace=False)\n",
      "  (8): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (9): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): ReLU()\n",
      "  (11): Dropout2d(p=0.5, inplace=False)\n",
      "  (12): Linear(in_features=1024, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for name in model.children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a31e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.layer1.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25e4ad2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 layer, n_node: 1024, dropratio: 0.50\n",
      "Correct of train: 57.89, dev: 38.46, test: 25.00\n",
      "0.."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type MyVGG. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "[0/20] loss: 1.157,  Correct of train: 50.00, dev: 23.08, test:50.00,  time: 251.80 sec..\n",
      "1.."
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 134217728 bytes. Error code 12 (Cannot allocate memory)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f4d5e5095af1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/optim/adam.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 134217728 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "total_time = 0\n",
    "disp_step = 10\n",
    "\n",
    "to_train = True\n",
    "if(to_train==False):\n",
    "    netname = './nets/fruit_vgg19_10.pkl'\n",
    "    model = torch.load(netname)\n",
    "else:\n",
    "    print(\"3 layer, n_node: %d, dropratio: %.2f\" %(n_node, dropratio))\n",
    "    model.eval() #evaluation(test) mode로 바꾸기 ->dropout batch normalization에 영향을 줌\n",
    "    train_corr = utils.ComputeCorr(train_batch, model)\n",
    "    dev_corr = utils.ComputeCorr(dev_batch, model)\n",
    "    test_corr = utils.ComputeCorr(test_batch, model)\n",
    "    print(\"Correct of train: %.2f, dev: %.2f, test: %.2f\"\n",
    "         %(train_corr, dev_corr, test_corr))\n",
    "    model.train()\n",
    "    \n",
    "    netname = './nets/fruit_vgg19'\n",
    "    \n",
    "    #graph그리기\n",
    "    x_epoch = []\n",
    "    y_train_err = []\n",
    "    y_dev_err = []\n",
    "    y_test_err = []\n",
    "    \n",
    "    x_epoch.append(0)\n",
    "    y_train_err.append(100.0 - train_corr)\n",
    "    y_dev_err.append(100.0 - dev_corr)\n",
    "    y_test_err.append(100.0 - test_corr)\n",
    "    \n",
    "#     #학습을 재시작한다면 \n",
    "#     netname = '../nets/fruit_vgg19_10.pkl'\n",
    "#     model = torch.load(netname)\n",
    "#     #파라미터 학습 여부 결정\n",
    "#     for params in model.layer0.parameters():\n",
    "#         params.required_grad = False\n",
    "#     for params in model.layer1.parameters():\n",
    "#         params.required_grad = True\n",
    "#     for i in range(1, epoch): #앞의 숫자를 시작할 epoch수로 변경시키기\n",
    "    \n",
    "    #재시작하지 않는다면\n",
    "    for i in range(epoch):\n",
    "        start_time = time.time()\n",
    "        print(\"%d..\" %i),\n",
    "        for img,label in train_batch:\n",
    "            img = Variable(img)#.cuda()\n",
    "            label = Variable(label)#.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(img)\n",
    "            loss = loss_func(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        total_time += duration\n",
    "        if(i % disp_step == 0) or (i==epoch-1):\n",
    "            torch.save(model, netname+'_%d.pkl'%i, )\n",
    "            print(\"\\n[%d/%d] loss: %.3f, \"%(i,epoch,(loss.cpu()).data.numpy())),\n",
    "            \n",
    "            #evaluation(test) mode로 바꾸기 -> dropout, batch_noramalization에 영향을 줌\n",
    "            model.eval()\n",
    "            \n",
    "            #train,dev, trian accr\n",
    "            train_corr = utils.ComputeCorr(train_batch, model)\n",
    "            dev_corr = utils.ComputeCorr(dev_batch, model)\n",
    "            test_corr = utils.ComputeCorr(test_batch, model)\n",
    "            print(\"Correct of train: %.2f, dev: %.2f, test:%.2f, \"\n",
    "                 %(train_corr,dev_corr,test_corr)),\n",
    "            model.train()\n",
    "            print(\"time: %.2f sec..\" %(total_time))\n",
    "            \n",
    "            #graph 그리기\n",
    "            x_epoch.append(i+1)\n",
    "            y_train_err.append(100.0 - train_corr)\n",
    "            y_dev_err.append(100.0 - dev_corr)\n",
    "            y_test_err.append(100.0 - test_corr)\n",
    "    print(\"Total time: %.2f sec\" %total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57bb118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p27",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
